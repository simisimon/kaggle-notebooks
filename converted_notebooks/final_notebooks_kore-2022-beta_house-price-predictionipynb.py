#!/usr/bin/env python
# coding: utf-8

# # House Buying Prediction using Python

# First we have importing necessary libraries of python, to perform such tasks. Here we have imported libraries like:
# 
# * **1) pandas (This library is used for data analysis)**
# * **2) numpy  (This library is used for mathematical operations)**
# * **3) matplotlib (This library is used for creating static, and interactive visuals)**

# In[ ]:


import pandas as pd
import numpy as np
import matplotlib.pyplot as pl


# In[ ]:


ds = pd.read_csv('sample_submission.csv')
ds


# 	Id	SalePrice
# * 0	1461	169277.052498
# * 1	1462	187758.393989
# * 2	1463	183583.683570
# * 3	1464	179317.477511
# * 4	1465	150730.079977
# * ...	...	...
# * 1454	2915	167081.220949
# * 1455	2916	164788.778231
# * 1456	2917	219222.423400
# * 1457	2918	184924.279659
# * 1458	2919	187741.866657
# * 1459 rows Ã— 2 columns

# In[ ]:


x = ds.iloc[:,0].values.reshape(-1,1)
y = ds.iloc[:,1].values.reshape(-1,1)


# In[ ]:


pl.plot(y, color='Orange')


# ![image.png](attachment:cfec086b-14bd-4fd5-b51c-6f024084d205.png)

# In[ ]:


pl.plot(x, color='Red')


# ![image.png](attachment:464a2f32-6104-473e-a54b-7ebbe855709c.png)

# In[ ]:


pl.scatter(x, y)
pl.show()


# ![image.png](attachment:9010bf69-3534-4e2c-aa91-77e80ac5310e.png)

# In[ ]:


from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)


# In[ ]:


from sklearn.preprocessing import StandardScaler

sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)


# In[ ]:


from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor()
rf.fit(x_train, y_train)


# RandomForestRegressor()

# In[ ]:


y_pred = rf.predict(x_test)
y_pred


# array([192587.13841559, 184268.61176386, 187712.71807012, 148427.70681331,
#        218982.16467775, 182913.39197618, 181671.1199566 , 178759.44906543,
#        180929.44773873, 180979.0790826 , 170644.53349683, 194950.2835116 ,
#        181438.02131946, 157610.35936114, 164922.02098409, 184552.38415192,
#        179487.2246305 , 178308.62681168, 159202.07619053, 179470.18771806,
#        189321.27326394, 164068.90321396, 182093.53262492, 186596.62073349,
#        158809.41636103, 177795.60488882, 190941.23056276, 174737.87807936,
#        166655.82758824, 177856.3280743 , 159531.55880945, 183194.50965373,
#        159354.709129  , 190263.08699794, 180921.47272478, 165927.58414619,
#        160659.63592007, 160868.71311203, 170176.25510777, 166085.84522326,
#        177040.51443905, 197134.54749313, 181999.52127678, 175453.3752159 ,
#        179547.0521036 , 183242.30583305, 172903.97305738, 184876.76391363,
#        182083.03803013, 173987.40985992, 167274.57090838, 181996.24831597,
#        226735.03391722, 163071.8064636 , 172665.2164738 , 167967.38486334,
#        175241.27230895, 209469.54621478, 185710.7095721 , 174889.80368637,
#        175775.71145462, 177357.00912584, 173511.69873738, 176409.06654482,
#        181380.29734081, 180156.20476876, 178297.12878501, 172024.83604393,
#        176968.05727673, 179758.98441452, 159986.7830084 , 169696.37273567,
#        177539.04420101, 176002.33348272, 178316.36149378, 172894.85255504,
#        175677.79334097, 175139.48341401, 179440.23260483, 187009.29238828,
#        184542.22623426, 168793.87657915, 154137.06750711, 164420.59245273,
#        186647.17987831, 178245.54816564, 202307.98543   , 169427.36874043,
#        151524.4918725 , 168345.23059899, 173913.8838029 , 173341.79992346,
#        163691.2409296 , 168961.9271458 , 168079.33338101, 165118.13315203,
#        187488.97587906, 172522.63681625, 186490.99744417, 177811.79921802,
#        179913.63742066, 180368.35723765, 180429.24687013, 184124.72037718,
#        159572.60821176, 173800.21196342, 187505.77940808, 197590.79562772,
#        194439.96382369, 179659.91003239, 162901.68004559, 191899.43949216,
#        178745.82462281, 181017.79673202, 184655.32772822, 175584.48989557,
#        177647.05112554, 184253.23011524, 196372.38232679, 190815.58363989,
#        178376.85412585, 193815.97418183, 166958.03282962, 175074.61085376,
#        181387.00033815, 178095.49375913, 182525.90367049, 171352.02513542,
#        179123.62589345, 177792.08861447, 207048.05305788, 158757.84292506,
#        195243.25365569, 192081.36560138, 181455.9264239 , 187667.84697609,
#        179135.45364564, 185054.94306511, 183136.8131774 , 180743.05806535,
#        161473.75401275, 177547.49525353, 183780.52385518, 166587.16051779,
#        176177.04791106, 152521.97527507, 183702.83953463, 162142.90084831,
#        182862.67240835, 174128.09900259, 177526.6682118 , 182162.25707793,
#        194108.35150583, 177693.56011498, 164576.81536268, 180018.11291466,
#        171338.41098046, 176072.65007585, 177824.71694031, 167231.87185393,
#        186794.52566568, 165709.69094408, 183682.0337268 , 177495.76523066,
#        170130.53502014, 164187.57316348, 186239.03521543, 177967.41780601,
#        183448.05456141, 178667.95961084, 183601.34727582, 162554.28103345,
#        187518.59808732, 177724.29984522, 186614.47284685, 170008.75516375,
#        188565.35881573, 160785.81536093, 180814.64895784, 187569.06833094,
#        187202.21929314, 172498.11032356, 175724.60037454, 153338.20357535,
#        164718.45060764, 183337.80601513, 198460.65312271, 174963.84758641,
#        183029.54380435, 168642.10642053, 165812.47266722, 201042.32551949,
#        179770.93028287, 168814.81293283, 177917.70623191, 207144.46989935,
#        180351.82541877, 187597.70093771, 183860.62388156, 166382.34774959,
#        168517.05175242, 168060.53163732, 177412.27452457, 173225.26470956,
#        182104.40281326, 176875.55278392, 161926.22657438, 184868.67070134,
#        183061.20463498, 170501.02612963, 172014.09547183, 178029.56100266,
#        176981.13371125, 172478.88503075, 188316.61873447, 182344.29523953,
#        190116.16569497, 164200.14529625, 157045.33889159, 157813.95441979,
#        175569.3857938 , 183592.41924257, 182702.85748339, 204869.94998856,
#        195297.09052757, 179771.76605152, 176659.18734179, 178843.51613017,
#        188023.64595885, 154268.26862202, 168452.35684904, 183142.9125929 ,
#        181274.77660343, 178459.23277378, 176516.15122737, 148806.06142007,
#        182964.09209696, 191562.59855229, 184613.95243144, 184814.90053703,
#        176115.0032465 , 171697.21624103, 166587.47165552, 174361.62935943,
#        183821.4081958 , 165949.96985007, 158454.44745146, 194710.16657431,
#        184220.46393018, 198233.12182586, 182331.44852137, 180498.75826325,
#        169923.26608808, 186349.15735956, 168436.83873151, 182515.41965398,
#        173029.88501251, 164348.51627583, 182821.03087099, 171204.24776269,
#        189030.86739753, 186385.3365517 , 172798.87212496, 194811.61888011,
#        180803.81066929, 179016.14722051, 166043.20048265, 195930.88826516,
#        180856.02562554, 172885.40747739, 171250.1773469 , 180444.02615373,
#        168703.35373893, 174002.96966302, 188231.01878341, 180794.531819  ,
#        168483.01350182, 181303.44787301, 210152.58909385, 176519.25431106,
#        171187.53484467, 201683.35487976, 174927.16630774, 192524.72916444,
#        179594.32771399, 164501.91945873, 185109.6012145 , 148484.24903007,
#        186815.62759519, 174652.03190852, 174454.10260236, 188371.11096594])

# In[ ]:


pl.plot(x_test, y_pred, color='Red')
pl.show()


# ![image.png](attachment:f3c42e67-064c-47de-a153-6e9e7ac0e60d.png)

# In[ ]:


pl.scatter(x_test, y_pred)
pl.plot(x_test, y_pred, color='Red')
pl.show()


# ![image.png](attachment:16bbc6c6-7a00-482a-8a54-eaf447bd2c35.png)

# In[ ]:


from sklearn import metrics

print('Mean absolute error:',metrics.mean_absolute_error(y_test,y_pred))


# **Mean absolute error: 178757.28060213334**

# In[ ]:


print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))


# **Mean Squared Error: 32234334196.429955**

# In[ ]:


print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))


# **Root Mean Squared Error: 179539.22745859734**

# In[ ]:




